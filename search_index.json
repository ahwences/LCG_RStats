[["index.html", "Probability and Statistics Classes Statistics and R Course, LCG 1 Preface", " Probability and Statistics Classes Statistics and R Course, LCG Alejandro Hernández Wences 1 Preface This notes are intended to guide and summarize the probability and statistics classes in the “Statistics and R” course of the Genomic Sciences program at the UNAM. Their intention is not to provide a formal and complete exposition of the subjects but rather just to serve as guidelines and visual aids during the classes. They may be useful for students taking notes by providing them with a general organization of the topics seen during the class, however they are no replacement for the notes that students are encouraged to take on their own. "],["probability-spaces-and-random-variables.html", "2 Probability Spaces and Random Variables 2.1 Probability Spaces 2.2 Properties of Probability Measures 2.3 Random Variables and CDFs 2.4 Expectations and Moments", " 2 Probability Spaces and Random Variables 2.1 Probability Spaces Let \\(\\Omega\\) be a set and let \\(\\mathcal{P}(\\Omega)\\) be its power set, i.e. the family \\(\\left\\{A\\colon A\\subset \\Omega\\right\\}\\). Definition 2.1 A family of sets \\(\\mathscr{F}\\subset \\mathcal{P}\\left(\\Omega\\right)\\) is called a \\(\\sigma\\)-algebra if it has the following properties: \\(\\Omega\\in\\mathscr{F}\\) and \\(\\emptyset\\in\\mathscr{F}\\). If \\(A\\in\\mathscr{F}\\) then \\(A^c\\in\\mathscr{F}\\). If \\((A_n)_{n\\in\\mathbb{N}}\\subset\\mathscr{F}\\) is a countable collection of subsets in \\(\\mathscr{F}\\), then \\[\\bigcup_{n=1}^\\infty A_n\\in\\mathscr{F}.\\] I.e. \\(\\mathscr{F}\\) is closed under countable unions. The pair \\((\\Omega,\\mathscr{F})\\) is called a measurable space. Definition 2.2 Let \\((\\Omega,\\mathscr{F})\\) be a measurable space. A function \\[\\mathbb{P}\\colon \\mathscr{F}\\to \\mathbb{R}^+\\] is called a probability measure if it satisfies the following properties: \\(\\mathbb{P}(\\Omega) = 1\\) and \\(\\mathbb{P}(\\emptyset)=0\\). \\(\\mathbb{P}(A)\\geq 0\\) for all \\(A\\in\\mathscr{F}\\). If \\((A_n)_n\\subset \\mathscr{F}\\) is a countable collection of pairwise disjoint sets, i.e. \\[ A_i \\bigcap A_j = \\emptyset \\quad \\forall i\\neq j, \\] then \\[ \\mathbb{P}\\left(\\bigcup_n A_n\\right) = \\sum_n \\mathbb{P}(A_n). \\] The triplet \\((\\Omega,\\mathscr{F},\\mathbb{P})\\) is called a probability space. 2.1.1 First Examples Example 2.1 Set \\(\\Omega=[0,1]\\), \\(\\mathscr{F}=\\mathscr{B}([0,1])\\) (safely ignore), and \\(\\mathbb{P}(A)=length(A)\\) E.g. If \\(A=[a,b]\\) then \\(\\mathbb{P}(A)=b-a\\) Example 2.2 Set \\(\\Omega=[0,1]^n\\), \\(\\mathscr{F}=\\mathscr{B}([0,1]^n)\\) (safely ignore), and \\(\\mathbb{P}(A)=volume(A)\\), E.g. If \\(n=2\\) and \\(A=[a,b]\\times[c,d]\\) then \\(\\mathbb{P}(A)=(b-a)(d-c)\\). E.g. In this case \\(\\mathbb{P}\\left(A\\right)=\\sum_{n=1}^\\infty \\left(\\frac{1}{2^2}\\right)^n = 1/3\\). 2.1.2 Important Examples 2.1.2.1 Probability Measures with Density on \\(\\mathbb{R}\\) (or \\(\\mathbb{R}^+\\), etc) Definition 2.3 (Probability Measure with Density) Let \\(f\\colon D\\subset\\mathbb{R}\\to \\mathbb{R}^+\\) be such that \\(\\int_D f(x)\\hspace{3pt}dx = 1\\). Such an \\(f\\) is called a density function on \\(D\\). Set \\(\\Omega=D\\), \\(\\mathscr{F}=\\mathscr{B}(D)\\) (safely ignore), and \\(\\mathbb{P}(A)=\\int_{A\\cap D} f(x) \\hspace{3pt}dx\\) E.g. If \\(D=\\mathbb{R}\\) and \\(A=[a,b]\\) then \\(\\mathbb{P}(A)=\\int_a^b f(x)\\hspace{3pt}dx\\). A probability measure with such representation is said to have density \\(f\\). Example 2.3 (Exponential Measure) Let \\(D=\\mathbb{R}^+\\). For any \\(\\lambda&gt;0\\) set \\[f(x)= \\lambda e^{-\\lambda x},\\] \\(f\\) satisfies \\[\\int_0^\\infty f(x) \\hspace{3pt}dx=\\int_0^\\infty \\lambda e^{-\\lambda x} \\hspace{3pt}dx= 1.\\] Thus we may define a continuous probability measure \\(\\mathbb{P}\\) on \\(\\mathbb{R}^+\\) which satisfies, for example \\[\\mathbb{P}([a,\\infty])=\\int_a^\\infty \\lambda e^{-\\lambda x}\\hspace{3pt}dx=e^{-\\lambda a}.\\] In this case \\(\\mathbb{P}[(2,\\infty)]=\\int_2^\\infty 0.5e^{-0.5x}\\hspace{3pt}dx = e^{-1}\\). 2.1.2.2 Discrete Probability Measures on \\(\\mathbb{R}\\) (or \\(\\mathbb{N}\\), etc) Definition 2.4 (Discrete Probability Measure) Let \\((a_n)_n\\subset\\mathbb{R}\\) be a countable collection of points in \\(\\mathbb{R}\\) (resp. \\(\\mathbb{N}\\), etc), and let \\((p_n)_n\\subset [0,1]\\) be such that \\[\\sum_n p_n = 1.\\] Set \\(\\Omega=\\mathbb{R}\\), \\(\\mathscr{F}=\\mathscr{B}(\\mathbb{R})\\) (safely ignore), \\[\\mathbb{P}(A)=\\sum_{n\\colon a_n\\in A}p_n \\] E.g. If \\(a_n=n\\) for \\(1\\leq n \\leq N\\) and \\(p_n=1/N\\), then \\(\\mathbb{P}(\\{1,2\\}) = \\frac{1}{N} + \\frac{1}{N}=\\frac{2}{N}\\) A probability measure that can be written in this way is called a discrete probability measure. Example 2.4 (Geometric Measure) Let \\(a_0=0, a_1=1, a_2=2, \\dots\\) and fix any \\(p\\in[0,1];\\) define \\(p_n=p^n(1-p)\\) for \\(n\\in\\{0,1,\\dots\\}\\) and note that they satisfy \\[ \\begin{aligned} \\sum_{n=0}^\\infty p^n(1-p) &amp;= (1-p)\\sum_{n=0}^\\infty p^n \\\\ &amp;= \\frac{1-p}{1-p} \\\\ &amp;= 1. \\end{aligned} \\] Thus we may define a probability measure \\(\\mathbb{P}\\) on \\(\\mathbb{N}\\) (or on \\(\\mathbb{R}\\)). For any \\(k\\in \\mathbb{N}\\) this probability measure evaluated on the set \\(\\{0,\\dots,k\\}\\) gives \\[ \\begin{aligned} \\mathbb{P}(\\{0,\\dots,k\\}) &amp;= (1-p)\\sum_{n=0}^k p^n \\\\ &amp;= (1-p)\\frac{1-p^{k+1}}{1-p}\\\\ &amp;=1-p^{k+1}. \\end{aligned} \\] Exercise 2.1 Invent one continuous probability measure and one discrete probability measure. Exercise 2.2 If \\(A,B\\in\\mathscr{F}\\) prove that \\[ \\mathbb{P}(A) = \\mathbb{P}(A\\cap B)+ \\mathbb{P}(A \\cap B^c). \\] If, furtheremore \\(B\\subset A\\), prove that \\[ \\mathbb{P}(A) = \\mathbb{P}(B) + \\mathbb{P}(A\\cap B^c) \\] and conclude that \\(\\mathbb{P}(B)\\leq\\mathbb{P}(A).\\) 2.2 Properties of Probability Measures Theorem 2.1 Let \\((B_n)_n\\subset\\mathscr{F}\\) be a partition of \\(\\Omega\\), i.e. \\(\\bigcup_n B_n = \\Omega\\), and \\(B_n \\bigcap B_m = \\emptyset \\quad \\forall n\\neq m\\), Then, for any \\(A\\in\\mathscr{F}\\) we have the following equality \\[ \\mathbb{P}\\left(A\\right) = \\sum_{n} \\mathbb{P}\\left(A\\bigcap B_n\\right). \\] Theorem 2.2 Let \\((\\Omega,\\mathscr{F}, \\mathbb{P})\\) be a probability space. The following equalities hold. If \\((A_n)_{n\\in\\mathbb{N}}\\subset \\mathscr{F}\\) and \\[ A_{n}\\subset A_{n+1} \\quad\\forall n\\in\\mathbb{N}, \\] then \\[ \\mathbb{P}\\left(\\bigcup_{n} A_n\\right) = \\lim_{n\\to\\infty} \\mathbb{P}\\left(A_n\\right). \\] If \\((A_n)_{n\\in\\mathbb{N}}\\subset \\mathscr{F}\\) and \\[ A_{n+1}\\subset A_{n} \\quad\\forall n\\in\\mathbb{N}, \\] then \\[ \\mathbb{P}\\left(\\bigcap_{n} A_n\\right) = \\lim_{n\\to\\infty} \\mathbb{P}\\left(A_n\\right). \\] 2.3 Random Variables and CDFs Definition 2.5 (Random Variable) Let \\((\\Omega, \\mathscr{F}, \\mathbb{P})\\) be a probability space. A function \\[ X\\colon \\Omega \\to \\mathbb{R} \\] is called a random variable. Definition 2.6 (Distribution) Let \\(X\\) be a random varaible defined on a probability space \\((\\Omega, \\mathscr{F}, \\mathbb{P})\\). The probability measure on \\(\\mathbb{R}\\) induced by \\(X\\), which is given by \\[ \\mathbb{P}(X\\in A) :=\\mathbb{P}\\left(\\left\\{\\omega\\in\\Omega\\colon X(\\omega)\\in A \\right\\}\\right), \\quad A\\in\\mathscr{B}(\\mathbb{R}), \\] is called its distribution or its law. Example 2.5 Recall Example 2.1 where \\(\\Omega = [0,1]\\) and \\(\\mathbb{P}(A)=length(A)\\). Let \\(N\\in\\mathbb{N}\\) and define the function \\(X\\colon [0,1]\\to\\mathbb{N}\\) given by \\[ X(\\omega):=n \\quad \\text{ if }\\quad \\frac{n-1}{N} \\leq \\omega \\leq \\frac{n}{N}, \\quad n\\in\\{1,\\dots,N\\}. \\] In this case \\(X\\) has the (discrete) uniform distribution on the set \\(\\{1,\\dots, N\\}\\) since all the points have the same probability measure, that is \\[ \\forall i,j\\in\\{1, \\dots, N\\},\\quad\\mathbb{P}(X=i)=\\frac{1}{N}=\\mathbb{P}(X=j). \\] Definition 2.7 (Cumulative Distribution Function) Let be a random varaible defined on a probability space \\((\\Omega, \\mathscr{F}, \\mathbb{P})\\). The function \\(F_X\\colon \\mathbb{R}\\to [0,1]\\) given by \\[ F_X(x) :=\\mathbb{P}\\left(X\\leq x\\right) \\] is called the cumulative distribution function (CDF) of \\(X\\). Example 2.6 Let \\(X\\) be a random variable with distribution function \\[ \\mathbb{P}(X\\in A) = \\frac{1}{b-a}\\int_{A}1 \\hspace{3pt}dx = length(A) / (b-a), \\quad A\\subset [a,b], \\] i.e. the (continuous) uniform distribution on the interval \\([a,b]\\) where \\(a&lt;b\\). Then the cumulative distribution function \\(F_X\\) of \\(X\\) is given by \\[ F_X(x) = \\begin{cases} 0 &amp;\\text{ if } x &lt; a,\\\\ \\frac{x-a}{b-a} &amp;\\text{ if }x \\in [a,b],\\\\ 1 &amp;\\text{ if } x \\geq b. \\end{cases} \\] a &lt;- 0 b &lt;- 3 x &lt;- seq(a-2, b+2, length.out = 100) par(&#39;plt&#39; = c(0.08, 1-0.05, 0.08, 1-0.05), &#39;xaxs&#39; = &quot;r&quot;, &#39;yaxs&#39; = &quot;r&quot;) plot(x = x, y = punif(x, min = a, max = b), type = &quot;l&quot;, col = &quot;skyblue3&quot;, lwd = 3) Exercise 2.3 Recall Example 2.4. Compute the CDF of the geometric distribution of parameter \\(p\\). Exercise 2.4 Recall Example 2.3. Compute the CDF of the exponential distribution of parameter \\(\\lambda\\). Example 2.7 (Plot Geometric CDF) p &lt;- 0.75 x &lt;- seq(-1, 6, length.out = 1000) par(&#39;plt&#39; = c(0.08, 1-0.05, 0.08, 1-0.05), &#39;xaxs&#39; = &quot;r&quot;, &#39;yaxs&#39; = &quot;r&quot;) plot(x = x, y = pgeom(x, p = p), type = &quot;p&quot;, col = &quot;skyblue3&quot;, lwd = 1) points(x = 0:5, y = pgeom(0:5, p = p), col = &quot;red&quot;, lwd = 3, pch = 19) ``` Example 2.8 (Plot Exponential CDF) lambda &lt;- 5 x &lt;- seq(0, 6, length.out = 1000) par(&#39;plt&#39; = c(0.08, 1-0.05, 0.08, 1-0.05), &#39;xaxs&#39; = &quot;r&quot;, &#39;yaxs&#39; = &quot;r&quot;) plot(x = x, y = pexp(x, rate = lambda), type = &quot;l&quot;, col = &quot;skyblue3&quot;, lwd = 3) Theorem 2.3 (Properties of CDFs) A function \\(F\\) is a cumulative distribution function if and only if \\(F(-\\infty):=\\lim_{x\\to-\\infty}F(x)=0\\) and \\(F(\\infty):=\\lim_{x\\to\\infty}F(x)=1\\). \\(F\\) is right continuous, i.e. for all \\(y\\in\\mathbb{R}\\), \\(\\lim_{x\\downarrow y} F(x) = F(y)\\). \\(F\\) is non-decreasing, i.e. for all \\(x&lt;y\\), \\(F(x)\\leq F(y)\\). Theorem 2.4 Let \\(X\\) and \\(Y\\) be two random variables. Then \\(X\\) and \\(Y\\) have the same distribution if and only if \\(F_X=F_Y\\). Definition 2.8 (Continuous and Discrete Random Variables) Let \\(X\\) be random variable. \\(X\\) is a continuous continuous random varible if \\(F_X\\) is continuous. \\(X\\) is a discrete random variable if \\(F_X\\) is piecewise constant. Remark. It is possible that a random variable \\(X\\) is not continuous nor discrete. In this course we will assume that continuous random variables have a probability distribution with a density (recall Definition 2.3 ), or, in other words, we will assume that for any continuous random variable \\(X\\) with CDF \\(F_X\\), we have \\(F_X&#39;=f_X\\) for some density function \\(f_X\\) and \\[ F_X(x) = \\int_{-\\infty}^x f_X(s) \\hspace{3pt}ds. \\] 2.4 Expectations and Moments Definition 2.9 (Expectation) Let \\(X\\) be a random variable and \\(h\\colon \\mathbb{R}\\to\\mathbb{R}\\) be a function. If \\(X\\) is continuous with density \\(f_X\\) \\[ \\mathbb{E}\\left[h(X)\\right] :=\\int_{-\\infty}^\\infty h(x)f_X(x)\\hspace{3pt}dx. \\] If \\(X\\) is discrete and takes values \\((a_n)_n\\) with probabilities \\((p_n)_n\\) \\[ \\mathbb{E}\\left[h(X)\\right] = \\sum_{n} p_n h(a:n). \\] "],["common-distributions.html", "3 Common Distributions", " 3 Common Distributions "]]
