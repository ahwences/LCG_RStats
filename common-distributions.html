<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Common Distributions | Probability and Statistics Classes</title>
  <meta name="description" content="3 Common Distributions | Probability and Statistics Classes" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Common Distributions | Probability and Statistics Classes" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Common Distributions | Probability and Statistics Classes" />
  
  
  

<meta name="author" content="Alejandro HernÃ¡ndez Wences" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="probability-spaces-and-random-variables.html"/>
<link rel="next" href="introduction-to-statistics.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html"><i class="fa fa-check"></i><b>2</b> Probability Spaces and Random Variables</a><ul>
<li class="chapter" data-level="2.1" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#probability-spaces"><i class="fa fa-check"></i><b>2.1</b> Probability Spaces</a><ul>
<li class="chapter" data-level="2.1.1" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#definition"><i class="fa fa-check"></i><b>2.1.1</b> Definition</a></li>
<li class="chapter" data-level="2.1.2" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#first-examples"><i class="fa fa-check"></i><b>2.1.2</b> First Examples</a></li>
<li class="chapter" data-level="2.1.3" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#continuousDiscreteDists"><i class="fa fa-check"></i><b>2.1.3</b> Important Examples</a></li>
<li class="chapter" data-level="2.1.4" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#properties-of-probability-measures"><i class="fa fa-check"></i><b>2.1.4</b> Properties of Probability Measures</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#random-elements"><i class="fa fa-check"></i><b>2.2</b> Random Elements</a><ul>
<li class="chapter" data-level="2.2.1" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#single-random-variables"><i class="fa fa-check"></i><b>2.2.1</b> Single Random Variables</a></li>
<li class="chapter" data-level="2.2.2" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#random-vectors"><i class="fa fa-check"></i><b>2.2.2</b> Random Vectors</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>2.3</b> Conditional Probability and Independence</a><ul>
<li class="chapter" data-level="2.3.1" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#intuition"><i class="fa fa-check"></i><b>2.3.1</b> Intuition</a></li>
<li class="chapter" data-level="2.3.2" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#discrete-case"><i class="fa fa-check"></i><b>2.3.2</b> Discrete case</a></li>
<li class="chapter" data-level="2.3.3" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#continuous-case"><i class="fa fa-check"></i><b>2.3.3</b> Continuous Case</a></li>
<li class="chapter" data-level="2.3.4" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#independence"><i class="fa fa-check"></i><b>2.3.4</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#cumulative-distribution-functions-cdfs"><i class="fa fa-check"></i><b>2.4</b> Cumulative Distribution Functions (CDFs)</a><ul>
<li class="chapter" data-level="2.4.1" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#single-random-variables-1"><i class="fa fa-check"></i><b>2.4.1</b> Single Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#expectations-and-moments"><i class="fa fa-check"></i><b>2.5</b> Expectations and Moments</a><ul>
<li class="chapter" data-level="2.5.1" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#single-random-variables-2"><i class="fa fa-check"></i><b>2.5.1</b> Single Random Variables</a></li>
<li class="chapter" data-level="2.5.2" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#random-vectors-1"><i class="fa fa-check"></i><b>2.5.2</b> Random Vectors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="common-distributions.html"><a href="common-distributions.html"><i class="fa fa-check"></i><b>3</b> Common Distributions</a><ul>
<li class="chapter" data-level="3.1" data-path="common-distributions.html"><a href="common-distributions.html#bernoulli"><i class="fa fa-check"></i><b>3.1</b> Bernoulli</a><ul>
<li class="chapter" data-level="3.1.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-1"><i class="fa fa-check"></i><b>3.1.1</b> Definition</a></li>
<li class="chapter" data-level="3.1.2" data-path="common-distributions.html"><a href="common-distributions.html#model"><i class="fa fa-check"></i><b>3.1.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="common-distributions.html"><a href="common-distributions.html#geometric-distribution"><i class="fa fa-check"></i><b>3.2</b> Geometric Distribution</a><ul>
<li class="chapter" data-level="3.2.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-2"><i class="fa fa-check"></i><b>3.2.1</b> Definition</a></li>
<li class="chapter" data-level="3.2.2" data-path="common-distributions.html"><a href="common-distributions.html#model-1"><i class="fa fa-check"></i><b>3.2.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="common-distributions.html"><a href="common-distributions.html#exponential-distribution"><i class="fa fa-check"></i><b>3.3</b> Exponential Distribution</a><ul>
<li class="chapter" data-level="3.3.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-3"><i class="fa fa-check"></i><b>3.3.1</b> Definition</a></li>
<li class="chapter" data-level="3.3.2" data-path="common-distributions.html"><a href="common-distributions.html#model-2"><i class="fa fa-check"></i><b>3.3.2</b> Model</a></li>
<li class="chapter" data-level="3.3.3" data-path="common-distributions.html"><a href="common-distributions.html#important-properties"><i class="fa fa-check"></i><b>3.3.3</b> Important properties</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="common-distributions.html"><a href="common-distributions.html#binomial-distribution"><i class="fa fa-check"></i><b>3.4</b> Binomial Distribution</a><ul>
<li class="chapter" data-level="3.4.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-4"><i class="fa fa-check"></i><b>3.4.1</b> Definition</a></li>
<li class="chapter" data-level="3.4.2" data-path="common-distributions.html"><a href="common-distributions.html#model-3"><i class="fa fa-check"></i><b>3.4.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="common-distributions.html"><a href="common-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>3.5</b> Poisson Distribution</a><ul>
<li class="chapter" data-level="3.5.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-5"><i class="fa fa-check"></i><b>3.5.1</b> Definition</a></li>
<li class="chapter" data-level="3.5.2" data-path="common-distributions.html"><a href="common-distributions.html#model-4"><i class="fa fa-check"></i><b>3.5.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="common-distributions.html"><a href="common-distributions.html#gamma-distribution"><i class="fa fa-check"></i><b>3.6</b> Gamma Distribution</a><ul>
<li class="chapter" data-level="3.6.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-6"><i class="fa fa-check"></i><b>3.6.1</b> Definition</a></li>
<li class="chapter" data-level="3.6.2" data-path="common-distributions.html"><a href="common-distributions.html#model-5"><i class="fa fa-check"></i><b>3.6.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="common-distributions.html"><a href="common-distributions.html#beta-distribution"><i class="fa fa-check"></i><b>3.7</b> Beta Distribution</a><ul>
<li class="chapter" data-level="3.7.1" data-path="common-distributions.html"><a href="common-distributions.html#model-6"><i class="fa fa-check"></i><b>3.7.1</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="common-distributions.html"><a href="common-distributions.html#normalDistribution"><i class="fa fa-check"></i><b>3.8</b> Normal Distribution</a><ul>
<li class="chapter" data-level="3.8.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-7"><i class="fa fa-check"></i><b>3.8.1</b> Definition</a></li>
<li class="chapter" data-level="3.8.2" data-path="common-distributions.html"><a href="common-distributions.html#model-7"><i class="fa fa-check"></i><b>3.8.2</b> Model</a></li>
<li class="chapter" data-level="3.8.3" data-path="common-distributions.html"><a href="common-distributions.html#important-properties-1"><i class="fa fa-check"></i><b>3.8.3</b> Important properties</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="common-distributions.html"><a href="common-distributions.html#students-t-distribution"><i class="fa fa-check"></i><b>3.9</b> Studentâs t-distribution</a><ul>
<li class="chapter" data-level="3.9.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-8"><i class="fa fa-check"></i><b>3.9.1</b> Definition</a></li>
<li class="chapter" data-level="3.9.2" data-path="common-distributions.html"><a href="common-distributions.html#model-8"><i class="fa fa-check"></i><b>3.9.2</b> Model</a></li>
<li class="chapter" data-level="3.9.3" data-path="common-distributions.html"><a href="common-distributions.html#cauchy-vs-normal"><i class="fa fa-check"></i><b>3.9.3</b> Cauchy VS Normal</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html"><i class="fa fa-check"></i><b>4</b> Introduction to Statistics</a><ul>
<li class="chapter" data-level="4.1" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#bigpicture"><i class="fa fa-check"></i><b>4.1</b> Big Picture</a><ul>
<li class="chapter" data-level="4.1.1" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#data"><i class="fa fa-check"></i><b>4.1.1</b> Data</a></li>
<li class="chapter" data-level="4.1.2" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#models"><i class="fa fa-check"></i><b>4.1.2</b> Models</a></li>
<li class="chapter" data-level="4.1.3" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#probability"><i class="fa fa-check"></i><b>4.1.3</b> Probability</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#likelihood-function"><i class="fa fa-check"></i><b>4.2</b> Likelihood Function</a><ul>
<li class="chapter" data-level="4.2.1" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#definition-9"><i class="fa fa-check"></i><b>4.2.1</b> Definition</a></li>
<li class="chapter" data-level="4.2.2" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#maximum-likelihood-estimator-mle-point-estimate"><i class="fa fa-check"></i><b>4.2.2</b> Maximum Likelihood Estimator MLE (Point Estimate)</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#hypothesis-testing"><i class="fa fa-check"></i><b>4.3</b> Hypothesis testing</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Probability and Statistics Classes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="common-distributions" class="section level1">
<h1><span class="header-section-number">3</span> Common Distributions</h1>
<div id="bernoulli" class="section level2">
<h2><span class="header-section-number">3.1</span> Bernoulli</h2>
<div id="definition-1" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Definition</h3>
<p>Let <span class="math inline">\(p\in(0,1)\)</span> be a parameter. The <em>bernoulli distribution</em> is the discrete probability distribution
that assigns a mass of <span class="math inline">\(p\)</span> to <span class="math inline">\(1\)</span>, and a mass of <span class="math inline">\(1-p\)</span> to <span class="math inline">\(0\)</span>; i.e.Â <span class="math inline">\(\mathbb{P}(\{1\})=p\)</span> and <span class="math inline">\(\mathbb{P}(\{0\})=1-p\)</span>.</p>
</div>
<div id="model" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Model</h3>
<p>The Bernoulli distribution is one of the most widely used distributions both in applied probability as well as
theoretical probability. For example the Bernoulli distribution can be seen as a building block of other
distributions such as the geometric distribution and the binomial distribution.</p>
<hr />
</div>
</div>
<div id="geometric-distribution" class="section level2">
<h2><span class="header-section-number">3.2</span> Geometric Distribution</h2>
<p>There are two distributions which share the common name of <em>geometric</em> distribution. For reasons that
will be clear later we call these two versions the <em>number of failures</em> version and <em>number of trials</em> version.</p>
<div id="definition-2" class="section level3">
<h3><span class="header-section-number">3.2.1</span> Definition</h3>
<div id="number-of-failures" class="section level4">
<h4><span class="header-section-number">3.2.1.1</span> Number of failures</h4>
<p>Let <span class="math inline">\(p\in (0,1)\)</span>. The geometric distribution (number of failures version)
is the discrete distribution in <span class="math inline">\(\{0, 1, \dots\}\)</span> such that
<span class="math display">\[
\mathbb{P}(X = k) = (1-p)p^k,\quad k\in \{0, 1, \dots\}.
\]</span></p>
<p><img src="_main_files/figure-html/unnamed-chunk-71-1.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-71-2.png" width="672" /></p>
<p><span class="math display">\[
\mathbb{E}[X] = \frac{p}{1-p},\quad \mathbb{Var}[X] = \frac{p}{(1-p)^2}.
\]</span></p>
</div>
<div id="number-of-trials" class="section level4">
<h4><span class="header-section-number">3.2.1.2</span> Number of trials</h4>
<p>Let <span class="math inline">\(p\in (0,1)\)</span>. The geometric distribution (number of failures version)
is the discrete distribution in <span class="math inline">\(\{1, \dots\}\)</span> such that
<span class="math display">\[
\mathbb{P}(X = k) = (1-p)p^{k-1},\quad k\in \{1, \dots\}.
\]</span></p>
<p><img src="_main_files/figure-html/unnamed-chunk-72-1.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-72-2.png" width="672" /></p>
<p><span class="math display">\[
\mathbb{E}[X] = \frac{1}{1-p},\quad \mathbb{Var}[X] = \frac{p}{(1-p)^2}.
\]</span></p>
</div>
</div>
<div id="model-1" class="section level3">
<h3><span class="header-section-number">3.2.2</span> Model</h3>
<p>The geometric distribution is used to model discrete waiting times until the occurrence of the first success in a series
of consecutive and <strong>independent</strong> trials (e.g.Â coin tosses).
It is easily proved that the waiting times modeled by the geometric distribution
have the <em>memorylessness</em> property, i.e.Â at any given time during the experiment the results of the past do not
affect the outcomes of the present/future, in particular the distribution of the remaining number of trials until the
first success given that <span class="math inline">\(k\)</span> failures have been encountered so far
is exactly the same as if the experiment were to be started all over again after, i.e.Â as if we decided to forget
that <span class="math inline">\(k\)</span> failures have been encountered so far.</p>
<div id="number-of-failures-1" class="section level4">
<h4><span class="header-section-number">3.2.2.1</span> Number of failures</h4>
<p>The canonical model for this distribution is the following: let <span class="math inline">\(p\in(0,1)\)</span> be a failure probability of some event.
For example you can think of <span class="math inline">\(p\)</span> as the probability that a coin toss is 'agila while <span class="math inline">\(1-p\)</span> is the probability
that it is sol. Let <span class="math inline">\(X\)</span> be the (random) number of 'agilas until the first sol appears. Then
<span class="math display">\[
\mathbb{P}(X = k) = p^k(1-p).
\]</span></p>
</div>
<div id="number-of-trials-1" class="section level4">
<h4><span class="header-section-number">3.2.2.2</span> Number of trials</h4>
<p>The canonical model for this distribution is the following: let <span class="math inline">\(p\in(0,1)\)</span> be a failure probability of some event.
For example you can think of <span class="math inline">\(p\)</span> as the probability that a coin toss is 'agila while <span class="math inline">\(1-p\)</span> is the probability
that it is sol. Let <span class="math inline">\(X\)</span> be the (random) number of trials until the first sol appears. Then
<span class="math display">\[
\mathbb{P}(X = k) = p^{k-1}(1-p).
\]</span></p>
<p>This distribution can thought of as the discrete version of the exponential distribution. To see this you can compare
<span class="math inline">\(\mathbb{P}(X&gt;k)\)</span> and <span class="math inline">\(\mathbb{P}(Y&gt; y)\)</span> where <span class="math inline">\(X\)</span> is geometrically distributed and <span class="math inline">\(Y\)</span> is exponentially distributed. We can also
compare their canonical models. They both model a probabilistic dynamic in which the future is independent of the past.</p>
<hr />
</div>
</div>
</div>
<div id="exponential-distribution" class="section level2">
<h2><span class="header-section-number">3.3</span> Exponential Distribution</h2>
<div id="definition-3" class="section level3">
<h3><span class="header-section-number">3.3.1</span> Definition</h3>
<p>The exponential distribution of parameter <span class="math inline">\(\lambda&gt;0\)</span> is the continuous distribution with density
<span class="math display">\[
\lambda e^{-\lambda x}.
\]</span></p>
<p><img src="_main_files/figure-html/unnamed-chunk-73-1.png" width="672" /></p>
</div>
<div id="model-2" class="section level3">
<h3><span class="header-section-number">3.3.2</span> Model</h3>
<p>The exponential distribution is used to model continuous waiting times until the first ocurrence of some event, where
intuitively such event is thought to occurr with some small probability in any given ``infinitesimalââ period of time
and <strong>independently</strong> of all other times. Thus, the waiting times modeled by the exponential distribution have the <em>memorylessness</em> property, i.e.Â at any given time during the experiment the results of the past do not
afect the outcomes of the present/future, in particular the distribution of the remaining waiting time until the
first occurence of the event given that we have already waited for <span class="math inline">\(t\)</span> units of time
is exactly the same as if we started the experiment all over again, i.e.Â as if we decided to forget that
we had already waited <span class="math inline">\(t\)</span> units of time.</p>
<p>In genomics this distribution is widely used in different modelling scenarios. For example exponential random variables
are used to model degradation and/or production times of molecules in biochemical models, they are also used in Population
Genetics to model birth/death times of individuals, or the occurrence of new mutations over time and/or along the genome.</p>
</div>
<div id="important-properties" class="section level3">
<h3><span class="header-section-number">3.3.3</span> Important properties</h3>
<div id="sum-of-exponentials" class="section level4">
<h4><span class="header-section-number">3.3.3.1</span> Sum of exponentials</h4>
<p>Let <span class="math inline">\(Y_1,\dots,Y_n\)</span> be exponentially distributed of parameter <span class="math inline">\(\lambda\)</span>. Then their sum
<span class="math display">\[
\sum_{k=1}^n Y_k
\]</span>
has Gamma distribution of parameters <span class="math inline">\(\alpha = n-1\)</span> and <span class="math inline">\(\beta = \lambda\)</span>.</p>
</div>
<div id="minimum-of-exponentials" class="section level4">
<h4><span class="header-section-number">3.3.3.2</span> Minimum of exponentials</h4>
<p>Let <span class="math inline">\(Y_1,\dots,Y_n\)</span> be exponentially distributed of parameters <span class="math inline">\(\lambda_1,\dots,\lambda_n\)</span>, and let
<span class="math display">\[
M = \min_{1\leq k\leq n} Y_k
\]</span>
be their minimum value,
and
<span class="math display">\[
I = \arg\min_{1\leq k\leq n} Y_k
\]</span>
be the index on <span class="math inline">\(\{1,\dots,n\}\)</span> that achieves the minimum. Then <span class="math inline">\(M\)</span> and <span class="math inline">\(I\)</span> are <strong>independent</strong> and <span class="math inline">\(M\)</span> is
exopnentially distributed of parameter <span class="math inline">\(\lambda_1+\dots +\lambda_n\)</span> while the distribution of <span class="math inline">\(I\)</span> is given by
<span class="math display">\[
\mathbb{P}(I=k) = \frac{\lambda_k}{\lambda_1+\dots +\lambda_n} \text{ for }1\leq k\leq n.
\]</span></p>
<hr />
</div>
</div>
</div>
<div id="binomial-distribution" class="section level2">
<h2><span class="header-section-number">3.4</span> Binomial Distribution</h2>
<div id="definition-4" class="section level3">
<h3><span class="header-section-number">3.4.1</span> Definition</h3>
<p>The bionomial distribution of parameters <span class="math inline">\(p,n\)</span> is the discrete distribution with values in <span class="math inline">\(\{0,\dots,n\}\)</span> such that, for
<span class="math inline">\(k\in\{0,\dots, n\}\)</span>,
<span class="math display">\[
\mathbb{P}\left(\{k\}\right) = \binom{n}{k}p^k(1-p)^{n-k}.
\]</span>
An easy way to corroborate that <span class="math inline">\(\sum_{k=0}^N \mathbb{P}\left(\{k\}\right) = 1\)</span> is to remember the expansion of <span class="math inline">\(1 = (p + 1-p)^N\)</span>.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-74-1.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-74-2.png" width="672" /></p>
</div>
<div id="model-3" class="section level3">
<h3><span class="header-section-number">3.4.2</span> Model</h3>
<p>The binomial distribution models the number of sucesses among <span class="math inline">\(n\)</span> <strong>independent</strong> trials, each with success probability
<span class="math inline">\(p\)</span>. The typical example is to count the number of tails in a series of <span class="math inline">\(n\)</span> coin tosses, where each coin toss is
tails with probability <span class="math inline">\(p\)</span> (if <span class="math inline">\(p=0.5\)</span> then the coin toss is said to be fair).</p>
<p>An alternative way to consruct the binomial distribution is to consider <span class="math inline">\(n\)</span> Bernoulli random variables, say <span class="math inline">\(X_1,\dots,X_n\)</span>,
of parameter <span class="math inline">\(p\)</span>, and then set <span class="math inline">\(Y=\sum_{k=1}^n X_k\)</span>. <span class="math inline">\(Y\)</span> is binomially distributed of parameters <span class="math inline">\(n,p.\)</span></p>
<hr />
</div>
</div>
<div id="poisson-distribution" class="section level2">
<h2><span class="header-section-number">3.5</span> Poisson Distribution</h2>
<div id="definition-5" class="section level3">
<h3><span class="header-section-number">3.5.1</span> Definition</h3>
<p>Let <span class="math inline">\(\lambda &gt; 0\)</span>. The Poisson distribution is the the discrete distribution given by
<span class="math display">\[
\mathbb{P}({n}) = e^{-\lambda} \frac{\lambda^n}{n!},\quad  \forall n\in\mathbb{Z}^+=\{0,1,2,\dots\}
\]</span></p>
<p><img src="_main_files/figure-html/unnamed-chunk-75-1.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-75-2.png" width="672" /></p>
</div>
<div id="model-4" class="section level3">
<h3><span class="header-section-number">3.5.2</span> Model</h3>
<p>The Poisson distribution appears in two intuitively equivalent situations:</p>
<ul>
<li>As the limit of a bionmial random variable of parameters <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span>, as <span class="math inline">\(n\to\infty\)</span> and <span class="math inline">\(np\to\lambda\)</span>. I.e. as
the random number of successes of an âinfiniteâ number of independent trials (<span class="math inline">\(n\to\infty\)</span>) each with an
âinfinitesimallâ probability of success (<span class="math inline">\(np\to\lambda\)</span>).</li>
<li>The Poisson distribution of parameter <span class="math inline">\(\lambda t\)</span> can be seen as the number of occurrences in a time interval <span class="math inline">\([0,t]\)</span>
of an event whose waiting times between two consecutevie occurrences are exponentialy distributed of parameter <span class="math inline">\(\lambda\)</span>.</li>
</ul>
<p>The Poisson distribution is the first option to model any random event that is known to have values in <span class="math inline">\(\{0,1,2,\dots\}\)</span>.
In genomics this distribution can be used to model the number of mutations in the genome, or in a given population that
had evolved over a period of time, or to model the number of children that each individual in a populatin produces
in the next generation, etc.</p>
<hr />
</div>
</div>
<div id="gamma-distribution" class="section level2">
<h2><span class="header-section-number">3.6</span> Gamma Distribution</h2>
<div id="definition-6" class="section level3">
<h3><span class="header-section-number">3.6.1</span> Definition</h3>
<p>The Gamma distribution of parameters <span class="math inline">\(\alpha&gt;0,\beta&gt;0\)</span> is the continuous distribution with density
<span class="math display">\[
f(x \vert \alpha,\beta) = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1}e^{-\beta x}.
\]</span>
where <span class="math inline">\(\Gamma\)</span> is the function defined by
<span class="math display">\[
\Gamma(s) =  \int_0^\infty t^{s-1} e^{-t} dt.
\]</span></p>
<p><img src="_main_files/figure-html/unnamed-chunk-76-1.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-76-2.png" width="672" /></p>
<p>Note from the the definition of <span class="math inline">\(f\)</span>, and also visualize it in the graphs above, that when <span class="math inline">\(\alpha=1\)</span> then we recover the
exponential distribution.</p>
</div>
<div id="model-5" class="section level3">
<h3><span class="header-section-number">3.6.2</span> Model</h3>
<p>The Gamma distribution is used to model random quantities that are known to be in <span class="math inline">\(\mathbb{R}^+\)</span> and that show departures
from the exponential distribution. Observe that the tail of the distribution decays exponentially.</p>
<hr />
</div>
</div>
<div id="beta-distribution" class="section level2">
<h2><span class="header-section-number">3.7</span> Beta Distribution</h2>
<p>The Gamma distribution of parameters <span class="math inline">\(\alpha&gt;0,\beta&gt;0\)</span> is the continuous distribution with density
<span class="math display">\[
f(x \vert \alpha,\beta) = \frac{1}{B(\alpha,\beta)} x^{\alpha-1}(1-x)^{\beta-1},
\]</span>
where <span class="math inline">\(B(\alpha,\beta)\)</span> is the Beta function given by
<span class="math display">\[
B(\alpha,\beta) =  \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)}.
\]</span></p>
<p><img src="_main_files/figure-html/unnamed-chunk-77-1.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-77-2.png" width="672" /></p>
<div id="model-6" class="section level3">
<h3><span class="header-section-number">3.7.1</span> Model</h3>
<p>The Beta distribution is a very versatile distribution to model random quantities in the interval [0,1]. For example
the Beta distribution can be used to model frequencies or probabilities.</p>
<hr />
</div>
</div>
<div id="normalDistribution" class="section level2">
<h2><span class="header-section-number">3.8</span> Normal Distribution</h2>
<div id="definition-7" class="section level3">
<h3><span class="header-section-number">3.8.1</span> Definition</h3>
<p>The normal distribution of parameters <span class="math inline">\(\mu\in\mathbb{R}\)</span> (the mean) and <span class="math inline">\(\sigma&gt;0\)</span> (the standard deviation)
is the continuous distribution with density
<span class="math display">\[
f(x \vert \mu,\sigma) = \frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
\]</span>
<img src="_main_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
</div>
<div id="model-7" class="section level3">
<h3><span class="header-section-number">3.8.2</span> Model</h3>
<p>The normal distribution is one of the most central distributions. Thanks to the Central Limit Theorem this distribution
appears everywhere, specially when the variables that we are modelling can be interpreted as averages over many copies of
subyacent independent random variables. This also explains why a lot of work in statistics is specialized to the study
of this distribution.</p>
</div>
<div id="important-properties-1" class="section level3">
<h3><span class="header-section-number">3.8.3</span> Important properties</h3>
<div id="locationscale-family" class="section level4">
<h4><span class="header-section-number">3.8.3.1</span> Location/scale family</h4>
<p>Let <span class="math inline">\(X\)</span> be a normall distributed random variable with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Then, for any <span class="math inline">\(a\in\mathbb{R}\)</span> and <span class="math inline">\(b&gt;0\)</span> the
random variable <span class="math inline">\(b(X+a)\)</span> is normally distibuted with mean <span class="math inline">\(b(\mu+a)\)</span> and variance <span class="math inline">\(b^2\sigma^2\)</span>.</p>
</div>
<div id="independence-of-normal-distributions" class="section level4">
<h4><span class="header-section-number">3.8.3.2</span> Independence of normal distributions</h4>
<p>Let <span class="math inline">\((X,Y)\)</span> be a random vector with (joint) normal distribution, then
<span class="math display">\[
X\perp Y \text{ iff } \mathbb{Cov}(X,Y) = 0.
\]</span></p>
</div>
<div id="sum-of-indpendent-normal-distributions" class="section level4">
<h4><span class="header-section-number">3.8.3.3</span> Sum of indpendent normal distributions</h4>
<p>Let <span class="math inline">\(Y_1,\dots,Y_n\)</span> be <span class="math inline">\(n\)</span> independent random variables with normal distribution of parameters <span class="math inline">\((\mu_1,\sigma_1), \dots, (\mu_n, \sigma_n)\)</span>.
Then the random variable <span class="math inline">\(\sum_{k=1}^n Y_k\)</span> is Normally distributed of parameters <span class="math inline">\(\mu = \sum_{k=1}^n \mu_k\)</span> and
<span class="math inline">\(\sigma^2 = \sum_{k=1}^n \sigma_k^2\)</span>.
Of course from this property we obtain that the sample mean of a sample of i.i.d normal distributions <span class="math inline">\((\mu,\sigma)\)</span>
<span class="math display">\[
\tilde{X}=\frac{1}{n}\sum_{k=1}^n X_k
\]</span>
is normally distributed with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(n\sigma^2\)</span>.</p>
</div>
<div id="sum-of-squares" class="section level4">
<h4><span class="header-section-number">3.8.3.4</span> Sum of squares</h4>
<p>Let <span class="math inline">\(Y_1,\dots,Y_n\)</span> be <span class="math inline">\(n\)</span> independent normally distributed radom variables with mean <span class="math inline">\(0\)</span> and variance <span class="math inline">\(1\)</span>. Then
the random varible <span class="math inline">\(\sum_{k=1}^n X_k^2\)</span> has Chi-squared distribution with <span class="math inline">\(n\)</span> degrees of freedom.</p>
</div>
<div id="sample-mean-and-sample-standard-deviation" class="section level4">
<h4><span class="header-section-number">3.8.3.5</span> Sample mean and sample standard deviation</h4>
<p>Let <span class="math inline">\(Y_1,\dots,Y_n\)</span> be <span class="math inline">\(n\)</span> independent normally distributed radom variables with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma\)</span>. Then
the sample mean
<span class="math display">\[
\tilde{X}
\]</span>
and the sample standard deviation
<span class="math display">\[
S = \frac{1}{n-1}\sum_{k=1}^n (X_k-\tilde{X})^2
\]</span>
are <strong>independent</strong> and the ratio
<span class="math display">\[
T = \frac{\tilde{X}- \mu}{S/\sqrt{n}}
\]</span>
has the t-student distribution of <span class="math inline">\(n-1\)</span> degrees of freedom.</p>
<hr />
</div>
</div>
</div>
<div id="students-t-distribution" class="section level2">
<h2><span class="header-section-number">3.9</span> Studentâs t-distribution</h2>
<div id="definition-8" class="section level3">
<h3><span class="header-section-number">3.9.1</span> Definition</h3>
<p>The students t-distribution of parameter <span class="math inline">\(\nu&gt;0\)</span> (degrees of freedom) is the continuous probability distribution with
density
<span class="math display">\[
f(x\vert \nu) = \frac{\Gamma(\frac{\nu+1}{2})}{\sqrt{\nu\pi}\Gamma(\nu/2)} \left(1+ \frac{x^2}{\nu}\right)^{-\frac{\nu+1}{2}}
\]</span></p>
<p><img src="_main_files/figure-html/unnamed-chunk-79-1.png" width="672" /></p>
</div>
<div id="model-8" class="section level3">
<h3><span class="header-section-number">3.9.2</span> Model</h3>
<p>The students t-disribution typically only appears in the statistical test comparing the sample means of two populations
which are assumed to have the normal distribution.</p>
<p>On the other hand, the students t-distribution can be used to model random quantities which show a similar overall
behaviour as a normally distributed random variable, but that at the same time allow for the ocurrence of extreme
(catastorphic) events, i.e.Â events where the value of the random quantity is realy large, which occur with low probability
but that still are not âimpossibleâ to see as is the case with normally distributed random variables whose
tails decay rather fast. In this regard, a typical
choice is the Cauchy distribution (the case when <span class="math inline">\(\nu=1\)</span> ) which has infinite variance.</p>
</div>
<div id="cauchy-vs-normal" class="section level3">
<h3><span class="header-section-number">3.9.3</span> Cauchy VS Normal</h3>
<p><img src="_main_files/figure-html/unnamed-chunk-80-1.png" width="672" /></p>
<p>See how the tails of the Cauchy distribution are much âfatâ that those of the normal distribution, but they both
have a âbellâ-like form. See a sequence of independent samples of each distribution, observe how the overall behaviour
seems to be quite similar, but from time to time the Cauchy distribution presents large values.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-81-1.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-81-2.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-81-3.png" width="672" /></p>
<hr />

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probability-spaces-and-random-variables.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="introduction-to-statistics.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
