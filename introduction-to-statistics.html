<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4 Introduction to Statistics | Probability and Statistics Classes</title>
  <meta name="description" content="4 Introduction to Statistics | Probability and Statistics Classes" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="4 Introduction to Statistics | Probability and Statistics Classes" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4 Introduction to Statistics | Probability and Statistics Classes" />
  
  
  

<meta name="author" content="Alejandro Hernández Wences" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="common-distributions.html"/>

<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface</a></li>
<li class="chapter" data-level="2" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html"><i class="fa fa-check"></i><b>2</b> Probability Spaces and Random Variables</a><ul>
<li class="chapter" data-level="2.1" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#probability-spaces"><i class="fa fa-check"></i><b>2.1</b> Probability Spaces</a><ul>
<li class="chapter" data-level="2.1.1" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#definition"><i class="fa fa-check"></i><b>2.1.1</b> Definition</a></li>
<li class="chapter" data-level="2.1.2" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#first-examples"><i class="fa fa-check"></i><b>2.1.2</b> First Examples</a></li>
<li class="chapter" data-level="2.1.3" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#continuousDiscreteDists"><i class="fa fa-check"></i><b>2.1.3</b> Important Examples</a></li>
<li class="chapter" data-level="2.1.4" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#properties-of-probability-measures"><i class="fa fa-check"></i><b>2.1.4</b> Properties of Probability Measures</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#random-elements"><i class="fa fa-check"></i><b>2.2</b> Random Elements</a><ul>
<li class="chapter" data-level="2.2.1" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#single-random-variables"><i class="fa fa-check"></i><b>2.2.1</b> Single Random Variables</a></li>
<li class="chapter" data-level="2.2.2" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#random-vectors"><i class="fa fa-check"></i><b>2.2.2</b> Random Vectors</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#conditional-probability-and-independence"><i class="fa fa-check"></i><b>2.3</b> Conditional Probability and Independence</a><ul>
<li class="chapter" data-level="2.3.1" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#intuition"><i class="fa fa-check"></i><b>2.3.1</b> Intuition</a></li>
<li class="chapter" data-level="2.3.2" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#discrete-case"><i class="fa fa-check"></i><b>2.3.2</b> Discrete case</a></li>
<li class="chapter" data-level="2.3.3" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#continuous-case"><i class="fa fa-check"></i><b>2.3.3</b> Continuous Case</a></li>
<li class="chapter" data-level="2.3.4" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#independence"><i class="fa fa-check"></i><b>2.3.4</b> Independence</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#cumulative-distribution-functions-cdfs"><i class="fa fa-check"></i><b>2.4</b> Cumulative Distribution Functions (CDFs)</a><ul>
<li class="chapter" data-level="2.4.1" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#single-random-variables-1"><i class="fa fa-check"></i><b>2.4.1</b> Single Random Variables</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#expectations-and-moments"><i class="fa fa-check"></i><b>2.5</b> Expectations and Moments</a><ul>
<li class="chapter" data-level="2.5.1" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#single-random-variables-2"><i class="fa fa-check"></i><b>2.5.1</b> Single Random Variables</a></li>
<li class="chapter" data-level="2.5.2" data-path="probability-spaces-and-random-variables.html"><a href="probability-spaces-and-random-variables.html#random-vectors-1"><i class="fa fa-check"></i><b>2.5.2</b> Random Vectors</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="common-distributions.html"><a href="common-distributions.html"><i class="fa fa-check"></i><b>3</b> Common Distributions</a><ul>
<li class="chapter" data-level="3.1" data-path="common-distributions.html"><a href="common-distributions.html#bernoulli"><i class="fa fa-check"></i><b>3.1</b> Bernoulli</a><ul>
<li class="chapter" data-level="3.1.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-1"><i class="fa fa-check"></i><b>3.1.1</b> Definition</a></li>
<li class="chapter" data-level="3.1.2" data-path="common-distributions.html"><a href="common-distributions.html#model"><i class="fa fa-check"></i><b>3.1.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="common-distributions.html"><a href="common-distributions.html#geometric-distribution"><i class="fa fa-check"></i><b>3.2</b> Geometric Distribution</a><ul>
<li class="chapter" data-level="3.2.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-2"><i class="fa fa-check"></i><b>3.2.1</b> Definition</a></li>
<li class="chapter" data-level="3.2.2" data-path="common-distributions.html"><a href="common-distributions.html#model-1"><i class="fa fa-check"></i><b>3.2.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="common-distributions.html"><a href="common-distributions.html#exponential-distribution"><i class="fa fa-check"></i><b>3.3</b> Exponential Distribution</a><ul>
<li class="chapter" data-level="3.3.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-3"><i class="fa fa-check"></i><b>3.3.1</b> Definition</a></li>
<li class="chapter" data-level="3.3.2" data-path="common-distributions.html"><a href="common-distributions.html#model-2"><i class="fa fa-check"></i><b>3.3.2</b> Model</a></li>
<li class="chapter" data-level="3.3.3" data-path="common-distributions.html"><a href="common-distributions.html#important-properties"><i class="fa fa-check"></i><b>3.3.3</b> Important properties</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="common-distributions.html"><a href="common-distributions.html#binomial-distribution"><i class="fa fa-check"></i><b>3.4</b> Binomial Distribution</a><ul>
<li class="chapter" data-level="3.4.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-4"><i class="fa fa-check"></i><b>3.4.1</b> Definition</a></li>
<li class="chapter" data-level="3.4.2" data-path="common-distributions.html"><a href="common-distributions.html#model-3"><i class="fa fa-check"></i><b>3.4.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="common-distributions.html"><a href="common-distributions.html#poisson-distribution"><i class="fa fa-check"></i><b>3.5</b> Poisson Distribution</a><ul>
<li class="chapter" data-level="3.5.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-5"><i class="fa fa-check"></i><b>3.5.1</b> Definition</a></li>
<li class="chapter" data-level="3.5.2" data-path="common-distributions.html"><a href="common-distributions.html#model-4"><i class="fa fa-check"></i><b>3.5.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="common-distributions.html"><a href="common-distributions.html#gamma-distribution"><i class="fa fa-check"></i><b>3.6</b> Gamma Distribution</a><ul>
<li class="chapter" data-level="3.6.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-6"><i class="fa fa-check"></i><b>3.6.1</b> Definition</a></li>
<li class="chapter" data-level="3.6.2" data-path="common-distributions.html"><a href="common-distributions.html#model-5"><i class="fa fa-check"></i><b>3.6.2</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="common-distributions.html"><a href="common-distributions.html#beta-distribution"><i class="fa fa-check"></i><b>3.7</b> Beta Distribution</a><ul>
<li class="chapter" data-level="3.7.1" data-path="common-distributions.html"><a href="common-distributions.html#model-6"><i class="fa fa-check"></i><b>3.7.1</b> Model</a></li>
</ul></li>
<li class="chapter" data-level="3.8" data-path="common-distributions.html"><a href="common-distributions.html#normalDistribution"><i class="fa fa-check"></i><b>3.8</b> Normal Distribution</a><ul>
<li class="chapter" data-level="3.8.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-7"><i class="fa fa-check"></i><b>3.8.1</b> Definition</a></li>
<li class="chapter" data-level="3.8.2" data-path="common-distributions.html"><a href="common-distributions.html#model-7"><i class="fa fa-check"></i><b>3.8.2</b> Model</a></li>
<li class="chapter" data-level="3.8.3" data-path="common-distributions.html"><a href="common-distributions.html#important-properties-1"><i class="fa fa-check"></i><b>3.8.3</b> Important properties</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="common-distributions.html"><a href="common-distributions.html#students-t-distribution"><i class="fa fa-check"></i><b>3.9</b> Student’s t-distribution</a><ul>
<li class="chapter" data-level="3.9.1" data-path="common-distributions.html"><a href="common-distributions.html#definition-8"><i class="fa fa-check"></i><b>3.9.1</b> Definition</a></li>
<li class="chapter" data-level="3.9.2" data-path="common-distributions.html"><a href="common-distributions.html#model-8"><i class="fa fa-check"></i><b>3.9.2</b> Model</a></li>
<li class="chapter" data-level="3.9.3" data-path="common-distributions.html"><a href="common-distributions.html#cauchy-vs-normal"><i class="fa fa-check"></i><b>3.9.3</b> Cauchy VS Normal</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html"><i class="fa fa-check"></i><b>4</b> Introduction to Statistics</a><ul>
<li class="chapter" data-level="4.1" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#bigpicture"><i class="fa fa-check"></i><b>4.1</b> Big Picture</a><ul>
<li class="chapter" data-level="4.1.1" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#data"><i class="fa fa-check"></i><b>4.1.1</b> Data</a></li>
<li class="chapter" data-level="4.1.2" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#models"><i class="fa fa-check"></i><b>4.1.2</b> Models</a></li>
<li class="chapter" data-level="4.1.3" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#probability"><i class="fa fa-check"></i><b>4.1.3</b> Probability</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#likelihood-function"><i class="fa fa-check"></i><b>4.2</b> Likelihood Function</a><ul>
<li class="chapter" data-level="4.2.1" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#definition-9"><i class="fa fa-check"></i><b>4.2.1</b> Definition</a></li>
<li class="chapter" data-level="4.2.2" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#maximum-likelihood-estimator-mle-point-estimate"><i class="fa fa-check"></i><b>4.2.2</b> Maximum Likelihood Estimator MLE (Point Estimate)</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="introduction-to-statistics.html"><a href="introduction-to-statistics.html#hypothesis-testing"><i class="fa fa-check"></i><b>4.3</b> Hypothesis testing</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Probability and Statistics Classes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="introduction-to-statistics" class="section level1">
<h1><span class="header-section-number">4</span> Introduction to Statistics</h1>
<div id="bigpicture" class="section level2">
<h2><span class="header-section-number">4.1</span> Big Picture</h2>
<div id="data" class="section level3">
<h3><span class="header-section-number">4.1.1</span> Data</h3>
<ul>
<li>Random variables live in the theoretical (mathematical) world</li>
<li>We <strong>assume</strong> that the variability of the data is adequately consistent
with the variability that <strong>would</strong> occur in a random sample from a given
distribution/random process.
<ul>
<li>Data itself is assumed to be random variables so that we can focus
on the best way to <strong>reason from random variables to inferences
about (theoretical) parameters</strong>.</li>
</ul></li>
<li>Beware, often the language of statistics takes a convenient shortcut by blurring the distinction between data and random variables.</li>
</ul>
</div>
<div id="models" class="section level3">
<h3><span class="header-section-number">4.1.2</span> Models</h3>
<ul>
<li>Incorporate theoretical assumptions and subjunctive statements (of the form if … then …).</li>
<li>Inference is based on what <strong>would</strong> happen if the data <strong>were</strong> to be random
variables distributed according to the statistical model.</li>
<li>The modelling assumption would be reasonable if the model were to <strong>describe accurately</strong> the variation in the data.</li>
<li>Typically one considers real observed data <span class="math inline">\(\bar{x}=(x_1,\dots,x_n)\)</span> on the one hand, and random vectors
<span class="math inline">\((X_1,\dots,X_n)\)</span> whose distribution depends on a parameter <span class="math inline">\(\theta\)</span> on the other. Then one assumes that the observed
data <span class="math inline">\(\bar{x}\)</span> is actually a realization of the random vector <span class="math inline">\(\bar{X}\)</span>, i.e one assumes that we have observed
the event
<span class="math inline">\(X_1=x_1,\dots,X_n=x_n\)</span> thus effectively considering the observed data <span class="math inline">\(\bar{x}\)</span> as random variables.</li>
</ul>
</div>
<div id="probability" class="section level3">
<h3><span class="header-section-number">4.1.3</span> Probability</h3>
<ul>
<li><strong>Aleatoric Probability:</strong> The use of probability to describe <strong>variation</strong>. E.g.
“The probability of rolling a 3 in a fair dice is 1/6”.</li>
<li><strong>Epistemic Probability:</strong> The use of probability to express <strong>knowledge</strong> (or beliefs). E.g. “I’m 90% sure that the capital of México is CDMX”.</li>
</ul>
</div>
</div>
<div id="likelihood-function" class="section level2">
<h2><span class="header-section-number">4.2</span> Likelihood Function</h2>
<div id="definition-9" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Definition</h3>

<div class="definition">
<span id="def:unnamed-chunk-82" class="definition"><strong>Definition 4.1  </strong></span>
Let <span class="math inline">\(\{\mathcal{P}_\theta\}_{\theta\in\Theta}\)</span>
be a set of probability models (e.g. distributions)
indexed by a (possibly a vector) parameter <span class="math inline">\(\theta\)</span> that lives
in some space <span class="math inline">\(\Theta\)</span> (e.g. <span class="math inline">\(\mathbb{R}^n\)</span>).
</div>

<ul>
<li><p>Assume that, for each
<span class="math inline">\(\theta\)</span>, if <span class="math inline">\(\bar{X}=(X_1,\dots,X_n)\)</span> is a random vector whose
distribution is given by <span class="math inline">\(\mathcal{P}_{\theta}\)</span>, then <span class="math inline">\(\bar{X}\)</span> has density
<span class="math inline">\(f(\bar{x}\vert \theta)\)</span>.</p></li>
<li><p>Fix <span class="math inline">\(\bar{x}=(x_1,\dots,x_n)\)</span>.</p></li>
</ul>
<p>The <strong>likelihood function</strong> <span class="math inline">\(L(\bar{x}\vert \theta)\)</span> based on <span class="math inline">\(\bar{x}\)</span> is the function
of <span class="math inline">\(\theta\)</span> given by
<span class="math display">\[L(\bar{x} \vert \theta) = f(\bar{x}\vert \theta).\]</span></p>

<div class="remark">
 <span class="remark"><em>Remark. </em></span> Note that if we regard
<span class="math display">\[
L(\bar{x} \vert \theta) = f(\bar{x}\vert \theta)
\]</span>
as a function of <span class="math inline">\(\bar{x}\)</span> (with <span class="math inline">\(\theta\)</span> fixed) instead, then what we have is simply
the density function of <span class="math inline">\(\bar{x}\)</span> under the model <span class="math inline">\(\mathcal{P}_\theta\)</span>.
</div>

<p>\</p>

<div class="example">
<p><span id="exm:unnamed-chunk-84" class="example"><strong>Example 4.1  (I.i.d Gamma)  </strong></span>Consider the family of probability models for a random vector <span class="math inline">\(\bar{X}\)</span>
of size <span class="math inline">\(n\)</span> whose entries are all independent and identically distributed
<span class="math inline">\(Gamma(\alpha,\beta)\)</span>. Then for any vector <span class="math inline">\(\bar{x}=(x_1,\dots,x_n)\)</span>, and
using the independence assumption for the first equality, we have
<span class="math display">\[
\begin{aligned}
L(\bar{x}\vert \alpha,\beta) &amp;= \prod_{i=1}^n L(x_i\vert \alpha,\beta) \\
&amp;= \left(\frac{\beta^\alpha}{\Gamma(\alpha)}\right)^n \prod_{i=1}^n x_i^{\alpha-1}e^{-\beta x_i}\\
&amp;=  \left(\frac{\beta^\alpha}{\Gamma(\alpha)}\right)^n \left(\prod_{i=1}^n x_i\right)^{\alpha-1}
e^{-\beta\sum_{k=1}^n x_i}.
\\
\end{aligned}.
\]</span></p>
</div>


<div class="example">
<span id="exm:unnamed-chunk-85" class="example"><strong>Example 4.2  (Independent but not identically distributed Gamma)  </strong></span>If we now change the family of models <span class="math inline">\(\{\mathcal{P_\theta}\}_{\theta\in\Theta}\)</span> of the previous example
and assume that the entries of <span class="math inline">\(\bar{X}\)</span> are still independent but ***
identically distributed, for example if we assume that <span class="math inline">\(X_i\)</span> has distribution
<span class="math inline">\(Gamma(\alpha_i, \beta)\)</span> (they share the parameter <span class="math inline">\(\beta\)</span> but not necessarily
the parameter <span class="math inline">\(\alpha\)</span>), then we obtain
<span class="math display">\[
\begin{aligned}
L(\bar{x}\vert \alpha,\beta) &amp;= \prod_{i=1}^n L(x_i\vert \alpha_i,\beta) \\
&amp;= \frac{\beta^{\sum_{i=1}^n \alpha_i}}{\prod_{i=1}^n\Gamma(\alpha_i)} 
    \left(\prod_{i=1}^n x_i^{\alpha_i-1}\right) e^{-\beta \sum_{i=1}^n x_i}
\\
\end{aligned}.
\]</span>
</div>


<div class="example">
<span id="exm:unnamed-chunk-86" class="example"><strong>Example 4.3  (Not independent nor indentically distributed Gamma )  </strong></span>Let <span class="math inline">\(Y_1,Y_2\)</span> be independent and exponentially distributed random variables of parameter <span class="math inline">\(\lambda&gt;0\)</span>. Define
the vector
<span class="math display">\[
(X_1,X_2) = (Y_1, Y_1+Y_2).
\]</span>
Then <span class="math inline">\(X_1\)</span> is <span class="math inline">\(Gamma(1,\lambda)\)</span>-distributed, <span class="math inline">\(X_2\)</span> is <span class="math inline">\(Gamma(2,\lambda)\)</span>-distributed, and clearly <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are not
independent. It can be seen that the density function <span class="math inline">\(f_{(X_1,X_2)}\)</span> is given by
<span class="math display">\[
f_{(X_1,X_2)}(x_1,x_2) = \begin{cases}
 \left(\lambda e^{-\lambda x_1}\right) \left(\lambda e^{-\lambda(x_2-x_1)}\right) &amp; \text{ if } x_2\geq x_1\\
  0 &amp; \text{ otherwise}.
\end{cases}
\]</span>
</div>

</div>
<div id="maximum-likelihood-estimator-mle-point-estimate" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Maximum Likelihood Estimator MLE (Point Estimate)</h3>
<p>The likelihood functions can be used to obtain a <strong>point estimate</strong> that
typically has very desirable properties.</p>

<div class="definition">
<span id="def:unnamed-chunk-87" class="definition"><strong>Definition 4.2  </strong></span>Let <span class="math inline">\(\{\mathcal{P}_\theta\}_{\theta\in\Theta}\)</span> be a family of probabilistic
models. Let <span class="math inline">\(\bar{x}=(x_1,\dots,x_n)\)</span> be a sample (a set of values). The
<strong>maximum likelihood</strong> estimator for <span class="math inline">\(\theta\)</span> based on the sample <span class="math inline">\(\bar{x}\)</span>
is given by
<span class="math display">\[
\hat{\theta}(\bar{x}) = arg\max_{\theta\in\Theta} L(\bar{x}\vert \theta),
\]</span>
it can be interpreted as the choice of <span class="math inline">\(\theta\)</span> under which
the data <span class="math inline">\(\bar{x}\)</span> is better explained
by <span class="math inline">\(\mathcal{P}_{\theta}\)</span>, where the
<strong>criterion</strong> used to compare models, i.e. to say that a model <span class="math inline">\(\mathcal{P}_{\theta_1}\)</span>
‘explains the data better’ than the model <span class="math inline">\(\mathcal{P}_{\theta_2}\)</span>,
is simply that of saying that it is more likely to observe the
data <span class="math inline">\(\bar{x}\)</span> under the model <span class="math inline">\(\mathcal{P}_{\theta_1}\)</span> than under the model <span class="math inline">\(\mathcal{P}_{\theta_2}\)</span>.
</div>


<div class="example">
<p><span id="exm:normalMuMLE" class="example"><strong>Example 4.4  </strong></span>Let <span class="math inline">\(\bar{X}=(X_1,\dots,X_n)\)</span> be i.i.d <span class="math inline">\(normal(\mu,1)\)</span>. Then,
for any sample point <span class="math inline">\(\bar{x}\)</span>, the likelihood function based on <span class="math inline">\(\bar{x}\)</span> is given by</p>
<p><span class="math display">\[
L(\bar{x}\vert \theta) = \frac{1}{(2\pi)^{n/2}} 
e^{-\frac{1}{2}\sum_{i=1}^n(x_i-\mu)^2}.
\]</span></p>
The equation
<span class="math display">\[
\frac{d}{d\mu}L(\bar{x} \vert \mu) = 0
\]</span>
reduces to
<span class="math display">\[
\sum_{k=1}^n(x_k-\mu) = 0
\]</span>
which has solution
<span class="math display">\[
\hat{\mu}(\bar{x}) = \frac{1}{n} \sum_{k=1}^N x_k = \tilde{x}.
\]</span>
</div>

<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" title="1"><span class="co">## Create (vectorized) likelihood function</span></a>
<a class="sourceLine" id="cb4-2" title="2">lnorm &lt;-<span class="st"> </span><span class="kw">Vectorize</span>( <span class="dt">FUN =</span> <span class="cf">function</span>(data, <span class="dt">mean =</span> <span class="dv">0</span>, <span class="dt">sd =</span> <span class="dv">1</span>){</a>
<a class="sourceLine" id="cb4-3" title="3">                            <span class="kw">return</span>(<span class="kw">prod</span>(<span class="kw">dnorm</span>(data, <span class="dt">mean =</span> mean, <span class="dt">sd =</span> sd)))</a>
<a class="sourceLine" id="cb4-4" title="4">                          },</a>
<a class="sourceLine" id="cb4-5" title="5">                    <span class="dt">vectorize.args =</span> <span class="kw">c</span>(<span class="st">&quot;mean&quot;</span>, <span class="st">&quot;sd&quot;</span>))</a>
<a class="sourceLine" id="cb4-6" title="6"></a>
<a class="sourceLine" id="cb4-7" title="7"><span class="co"># Generate random sample </span></a>
<a class="sourceLine" id="cb4-8" title="8">data &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">100</span>, <span class="dt">mean =</span> <span class="dv">1</span>, <span class="dt">sd =</span> <span class="dv">1</span>) <span class="co"># mu = 1 is the `real&#39; parameter</span></a>
<a class="sourceLine" id="cb4-9" title="9">mle &lt;-<span class="st"> </span><span class="kw">mean</span>(data)</a>
<a class="sourceLine" id="cb4-10" title="10"></a>
<a class="sourceLine" id="cb4-11" title="11"><span class="co"># Visualize likelihoods under different mus</span></a>
<a class="sourceLine" id="cb4-12" title="12">mus &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">2</span>, <span class="dt">length.out =</span> <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb4-13" title="13">lmus &lt;-<span class="st"> </span><span class="kw">lnorm</span>(data, <span class="dt">mean =</span> mus)</a>
<a class="sourceLine" id="cb4-14" title="14"><span class="kw">plot</span>(<span class="dt">x =</span> mus, <span class="dt">y =</span> lmus, <span class="dt">xlab =</span> <span class="kw">TeX</span>(<span class="st">&quot;$</span><span class="ch">\\</span><span class="st">mu$&quot;</span>), <span class="dt">ylab =</span> <span class="st">&quot;Likelihood&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>)</a>
<a class="sourceLine" id="cb4-15" title="15"><span class="kw">abline</span>(<span class="dt">v =</span> <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb4-16" title="16"><span class="kw">abline</span>(<span class="dt">v =</span> mle, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span> )</a>
<a class="sourceLine" id="cb4-17" title="17"><span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;MLE&quot;</span>, <span class="st">&quot;Truth&quot;</span>), <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">bty =</span> <span class="st">&quot;n&quot;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-88-1.png" width="672" /></p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" title="1"><span class="co"># Visualize estimated density VS normal densities under different mus</span></a>
<a class="sourceLine" id="cb5-2" title="2"><span class="kw">plot</span>(<span class="kw">density</span>(data), <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.5</span>), <span class="dt">lwd =</span> <span class="dv">3</span>, <span class="dt">xlab =</span> <span class="st">&quot;x&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;density&quot;</span>, <span class="dt">main =</span> <span class="ot">NA</span>)</a>
<a class="sourceLine" id="cb5-3" title="3">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>,<span class="dt">length.out =</span> <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb5-4" title="4">mus &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">length.out =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb5-5" title="5">ignore &lt;-<span class="st"> </span><span class="kw">mapply</span>(lines, <span class="dt">y =</span> <span class="kw">lapply</span>(mus, dnorm, <span class="dt">x =</span> x, <span class="dt">sd =</span> <span class="dv">1</span>), </a>
<a class="sourceLine" id="cb5-6" title="6">       <span class="dt">MoreArgs =</span> <span class="kw">list</span>(<span class="st">&#39;x&#39;</span> =<span class="st"> </span>x, <span class="st">&#39;col&#39;</span> =<span class="st"> &quot;gray&quot;</span>, <span class="st">&#39;lwd&#39;</span> =<span class="st"> </span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb5-7" title="7"><span class="kw">abline</span>(<span class="dt">v =</span> mus, <span class="dt">lwd =</span> <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;gray&quot;</span>)</a>
<a class="sourceLine" id="cb5-8" title="8"><span class="kw">lines</span>(x, <span class="kw">dnorm</span>(x, <span class="dt">mean =</span> <span class="dv">1</span>, <span class="dt">sd =</span> <span class="dv">1</span>), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb5-9" title="9"><span class="kw">abline</span>(<span class="dt">v =</span> <span class="dv">1</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb5-10" title="10"><span class="kw">lines</span>(x, <span class="kw">dnorm</span>(x, <span class="dt">mean =</span> mle, <span class="dt">sd =</span> <span class="dv">1</span>), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb5-11" title="11"><span class="kw">abline</span>(<span class="dt">v =</span> mle, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>)</a>
<a class="sourceLine" id="cb5-12" title="12"><span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="dt">box.col =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;mle&quot;</span>, <span class="st">&quot;truth&quot;</span>), <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="dt">lwd =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-88-2.png" width="672" /></p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb6-1" title="1"><span class="co"># Visualize estimated cdf VS normal cdfs under different mus</span></a>
<a class="sourceLine" id="cb6-2" title="2">datacdf &lt;-<span class="st"> </span><span class="kw">ecdf</span>(data)</a>
<a class="sourceLine" id="cb6-3" title="3">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>,<span class="dt">length.out =</span> <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb6-4" title="4"><span class="kw">plot</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">datacdf</span>(x), <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span>,<span class="dv">3</span>), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">xlab =</span> <span class="st">&quot;x&quot;</span>, <span class="dt">ylab =</span> <span class="st">&quot;CDF&quot;</span>, <span class="dt">main =</span> <span class="ot">NA</span>)</a>
<a class="sourceLine" id="cb6-5" title="5">mus &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">2</span>, <span class="dv">2</span>, <span class="dt">length.out =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb6-6" title="6">ignore &lt;-<span class="st"> </span><span class="kw">mapply</span>(lines, <span class="dt">y =</span> <span class="kw">lapply</span>(mus, pnorm, <span class="dt">q =</span> x, <span class="dt">sd =</span> <span class="dv">1</span>), </a>
<a class="sourceLine" id="cb6-7" title="7">       <span class="dt">MoreArgs =</span> <span class="kw">list</span>(<span class="st">&#39;x&#39;</span> =<span class="st"> </span>x, <span class="st">&#39;col&#39;</span> =<span class="st"> &quot;gray&quot;</span>, <span class="st">&#39;lwd&#39;</span> =<span class="st"> </span><span class="dv">1</span>))</a>
<a class="sourceLine" id="cb6-8" title="8"><span class="kw">lines</span>(x, <span class="kw">pnorm</span>(x, <span class="dt">mean =</span> <span class="dv">1</span>, <span class="dt">sd =</span> <span class="dv">1</span>), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb6-9" title="9"><span class="kw">lines</span>(x, <span class="kw">pnorm</span>(x, <span class="dt">mean =</span> mle, <span class="dt">sd =</span> <span class="dv">1</span>), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb6-10" title="10"><span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="dt">box.col =</span> <span class="st">&quot;white&quot;</span>, <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;data&quot;</span>, <span class="st">&quot;mle&quot;</span>, <span class="st">&quot;truth&quot;</span>), <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="dt">lwd =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-88-3.png" width="672" /></p>
<p>As discussed in Section <a href="introduction-to-statistics.html#bigpicture">4.1</a> the value <span class="math inline">\(\bar{x}\)</span> is typically equated with the experimentally observed data.
However, in the probabilistic world <span class="math inline">\(\bar{x}\)</span> is interpreted as just a ‘realization’ of the random vector <span class="math inline">\(\bar{X}\)</span>.
Now observe that <span class="math inline">\(\hat{\theta}(\bar{x})\)</span>, the MLE for <span class="math inline">\(\theta\)</span>, is a function of <span class="math inline">\(\bar{x}\)</span>,
and if we now think of <span class="math inline">\(\bar{x}\)</span> as a realization
of <span class="math inline">\(\bar{X}\)</span>, then in fact we may consider the random variable <span class="math inline">\(\hat{\theta}(\bar{X})\)</span>. Now, what does this mean
in our statistical framework? Well, if a particular value <span class="math inline">\(\bar{x}\)</span> is equated with the experimentally observed data, then we
can think of the experiment as a probabilistic procedure that outputs a random value <span class="math inline">\(\bar{x}\)</span> every
time it is performed, thus we think of the experiment as a sampling procedure of <span class="math inline">\(\bar{X}\)</span> under the ‘true’
distribution of <span class="math inline">\(\bar{X}\)</span>. Thus, our estimation, in particular the MLE point estimate, is random, is really a random variable,
so that we may study the probability that we provide a good estimate for the real distribution of <span class="math inline">\(\bar{X}\)</span>, or the
probability that we fail to do so.
In the particular case of the MLE point estimate we may, for example, study the difference of <span class="math inline">\(\hat{\theta}(\bar{X})\)</span> for
and the true value of <span class="math inline">\(\theta\)</span>, say <span class="math inline">\(\theta_0\)</span>.</p>

<div class="example">
<span id="exm:normalMuMLEdistribution" class="example"><strong>Example 4.5  </strong></span>Recall the situation of Example @ref{exm:normalMuMLE}. Assume that the ‘true’ distribution of <span class="math inline">\(\bar{X}\)</span> is
normal with mean <span class="math inline">\(\mu_0\)</span> and variance 1 and recall that
<span class="math inline">\(\hat{\mu}(\bar{X})= \tilde{X}\)</span> so that (see @ref{normalDistribution}) <span class="math inline">\(\hat{\mu}(\bar{X})\)</span> is again normally distributed with mean <span class="math inline">\(\mu_0\)</span> and variance <span class="math inline">\(1/n\)</span>.
</div>

<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" title="1"><span class="co"># Generate 1000 random samples of size 100 each</span></a>
<a class="sourceLine" id="cb7-2" title="2">mu0 &lt;-<span class="st"> </span><span class="dv">1</span></a>
<a class="sourceLine" id="cb7-3" title="3">datas &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(<span class="dv">10000</span><span class="op">*</span><span class="dv">100</span>, <span class="dt">mean =</span> mu0, <span class="dt">sd =</span> <span class="dv">1</span>), <span class="dt">nrow =</span> <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb7-4" title="4"><span class="co"># Compute MLE for each sample of size 100</span></a>
<a class="sourceLine" id="cb7-5" title="5">mles &lt;-<span class="st"> </span><span class="kw">colMeans</span>(datas)</a>
<a class="sourceLine" id="cb7-6" title="6"><span class="co"># Visualize MLE density and compare with true value mu0</span></a>
<a class="sourceLine" id="cb7-7" title="7"><span class="co"># Estimated density</span></a>
<a class="sourceLine" id="cb7-8" title="8"><span class="kw">plot</span>(<span class="kw">density</span>(mles), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">xlab =</span> <span class="kw">TeX</span>(<span class="st">&quot;$</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">mu}(</span><span class="ch">\\</span><span class="st">bar{x})$&quot;</span>), <span class="dt">ylab =</span> <span class="st">&quot;Density&quot;</span>, <span class="dt">main =</span> <span class="kw">TeX</span>(<span class="st">&quot;$</span><span class="ch">\\</span><span class="st">hat{</span><span class="ch">\\</span><span class="st">mu}(</span><span class="ch">\\</span><span class="st">bar{X})$ density&quot;</span>))</a>
<a class="sourceLine" id="cb7-9" title="9"><span class="co"># True density</span></a>
<a class="sourceLine" id="cb7-10" title="10">x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="fl">0.7</span>, <span class="fl">1.5</span>, <span class="dt">length.out =</span> <span class="dv">1000</span>)</a>
<a class="sourceLine" id="cb7-11" title="11"><span class="kw">lines</span>(<span class="dt">x =</span> x, <span class="dt">y =</span> <span class="kw">dnorm</span>(x, <span class="dt">mean =</span> mu0, <span class="dt">sd =</span> <span class="kw">sqrt</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">100</span>)), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb7-12" title="12"><span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>, <span class="dt">legend =</span> <span class="kw">c</span>(<span class="st">&quot;MLE sample density&quot;</span>, <span class="st">&quot;MLE true density&quot;</span>), <span class="dt">col =</span> <span class="kw">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">bty =</span> <span class="st">&quot;n&quot;</span>)</a>
<a class="sourceLine" id="cb7-13" title="13"><span class="kw">abline</span>(<span class="dt">v =</span> <span class="kw">mean</span>(mles), <span class="dt">col =</span> <span class="st">&quot;blue&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</a>
<a class="sourceLine" id="cb7-14" title="14"><span class="kw">abline</span>(<span class="dt">v =</span> mu0, <span class="dt">col =</span> <span class="st">&quot;black&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-89-1.png" width="672" /></p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" title="1"><span class="kw">summary</span>(mles)</a></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##  0.6539  0.9322  0.9992  0.9995  1.0663  1.3720</code></pre>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" title="1"><span class="kw">sd</span>(mles)</a></code></pre></div>
<pre><code>## [1] 0.09999539</code></pre>
<p>Thus, for example, we may compute the probability, under the <strong>assumption</strong> that the true value of <span class="math inline">\(\mu\)</span> is <span class="math inline">\(\mu_0\)</span>, that
<span class="math inline">\(\left\lvert \hat{\mu}(\bar{X}) - \mu_0 \right\rvert&gt; a\)</span>, we have
<span class="math display">\[
\mathbb{P}(\left\lvert \hat{\mu}(\bar{X}) - \mu_0 \right\rvert&gt; a) = \int_{\mu_0-a}^{\mu_0+a} \sqrt{\frac{n}{2\pi}} 
                   e^{-\frac{n(\hat{\mu} - \mu_0 )^2}{2}} d\hat{\mu} 
\]</span></p>
</div>
</div>
<div id="hypothesis-testing" class="section level2">
<h2><span class="header-section-number">4.3</span> Hypothesis testing</h2>

<div class="definition">
<span id="def:unnamed-chunk-90" class="definition"><strong>Definition 4.3  </strong></span>A <strong>hypothesis</strong> is a statement about a population/model parameter.
</div>

<p>The goal of a hypothesis test is to decide, based on a sample from the population, which of two complementary hypothesis is true.</p>

<div class="definition">
<span id="def:unnamed-chunk-91" class="definition"><strong>Definition 4.4  </strong></span>The two complementary hypothesis in a hypothesis testing problem are called
the <strong>null Hypothesis (<span class="math inline">\(H_0\)</span>)</strong> and the <strong>alternative hypothesis (<span class="math inline">\(H_1\)</span>)</strong>.
</div>

<p>\</p>

<div class="definition">
<p><span id="def:unnamed-chunk-92" class="definition"><strong>Definition 4.5  </strong></span>A <strong>hypothesis testing procedure</strong> as rule that sepecifies:</p>
<ol style="list-style-type: decimal">
<li>For which sample values the decision is made to accept <span class="math inline">\(H_0\)</span> as true.</li>
<li>For which sample values <span class="math inline">\(H_0\)</span> is rejected (in ``acceptance’’ of <span class="math inline">\(H_1\)</span>).</li>
</ol>
The region of the sample space on which <span class="math inline">\(H_0\)</span> is rejected is called the <strong>rejection region</strong>, while the region in which <span class="math inline">\(H_0\)</span> is accepted is called the
<strong>acceptance region</strong>.
</div>


</div>
</div>


























































            </section>

          </div>
        </div>
      </div>
<a href="common-distributions.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
